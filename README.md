

# Iris Classification Pipeline ğŸš€

**Data Science â€¢ Python â€¢ Machine Learning â€¢ KNN â€¢ EDA â€¢ Model Evaluation**

---

## ğŸ” DescripciÃ³n

Mini proyecto prÃ¡ctico de Data Science aplicado al clÃ¡sico dataset **Iris**.  
Demuestra un pipeline completo: exploraciÃ³n de datos, preprocesamiento, modelado (KNN), validaciÃ³n cruzada y evaluaciÃ³n con mÃ©tricas y matriz de confusiÃ³n. AnÃ¡lisis, reproducibilidad y machine learning bÃ¡sico.

---

## ğŸ§ª QuÃ© incluye este proyecto

- Carga y anÃ¡lisis exploratorio del dataset Iris  
- Escalado de features con `StandardScaler`  
- ClasificaciÃ³n con **K-Nearest Neighbors (KNN)**  
- ValidaciÃ³n cruzada estratificada (5 folds) para evaluar estabilidad  
- EvaluaciÃ³n final sobre test set independiente  
- Reporte de mÃ©tricas (accuracy, precision, recall, F1)  
- Matriz de confusiÃ³n visualizada  
- Pipeline reproducible con `scikit-learn`

---

## âš™ï¸ TecnologÃ­as

- Python 3  
- pandas  
- seaborn  
- matplotlib  
- scikit-learn  
- Git / GitHub

---

## ğŸš€ CÃ³mo reproducir

1. Clonar el repositorio:
   ```bash
   git clone https://github.com/tu-usuario/iris-classification.git
   cd iris-classification
2. Instalar dependencias (recomendado en un entorno virtual):
   pip install pandas seaborn matplotlib scikit-learn
3. Ejecutar el notebook:
   AbrÃ­ proyecto_iris.ipynb en Jupyter o Google Colab.
   O corrÃ© el script equivalente en Python.

---

ğŸ§  Resultado principal
Accuracy promedio en validaciÃ³n cruzada: muestra consistencia del modelo.
Accuracy en test set: evaluaciÃ³n realista con datos no vistos.
Reporte de clasificaciÃ³n: precision, recall y F1 por cada especie.
Matriz de confusiÃ³n: visualiza quÃ© clases se confunden.
Insight clave: setosa es fÃ¡cilmente separable; versicolor y virginica requieren combinaciÃ³n de features para distinguirse bien.

ğŸ“ˆ Insights / Aprendizajes
El escalado de features es crÃ­tico para modelos basados en distancia como KNN.
Las combinaciones de petal_length y petal_width son las mÃ¡s discriminantes.
ValidaciÃ³n cruzada ayuda a evitar conclusiones errÃ³neas por overfitting de un solo split.
MÃ©tricas desglosadas por clase revelan si el modelo favorece o perjudica alguna categorÃ­a.

ğŸ“¦ Estructura del repositorio
â”œâ”€â”€ proyecto_iris.ipynb      # Notebook con pipeline completo
â”œâ”€â”€ README.md               # Este archivo
â”œâ”€â”€ requirements.txt        # Dependencias (opcional)
â”œâ”€â”€ img/                    # Visualizaciones (matriz de confusiÃ³n, pairplot)

ğŸ“¬ Contacto
Si te interesa colaborar, dar feedback o tienes oportunidades en Data Science, contÃ¡ctame.
â­ Dale "Star" si te sirviÃ³ este proyecto.
